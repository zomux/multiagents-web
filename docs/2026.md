---
sidebar_position: 1
hide_table_of_contents: true
title: WMAC 2026 - Overview
slug: /2026
---


:::info
- (1/17) Room map is now available for the venue (see below), paper PDFs are now available.
- (1/8) Room assignment announced: **Topaz 220 – 225**
:::

:::info
Important: WMAC 2026 is a Bridge Program of AAAI 2026, rather than a standalone workshop. Please register with "AAAI Tutorial/Lab/Bridge only" option or "Bridges, Tutorials and Labs Add-on" when registering together with the main conference. The program date is January 20, 2026. **Room: Topaz 220 – 225**
:::

<div style={{backgroundColor: '#e8f5e9', padding: '1rem 1.5rem', borderRadius: '8px', marginBottom: '1.5rem', border: '1px solid #a5d6a7'}}>
  <strong>Workshop Check-In:</strong> Please <a href="/checkin/">check in here</a> when you arrive to receive your workshop goodies!
</div>

<div style={{backgroundColor: '#e3f2fd', padding: '1rem 1.5rem', borderRadius: '8px', marginBottom: '1.5rem', border: '1px solid #90caf9'}}>
  <strong>How to Ask Questions:</strong> You can ask questions related to the program or presenters through the following channels:
  <ul style={{marginBottom: 0, marginTop: '0.5rem'}}>
    <li><a href="https://discord.gg/nXqY8t3K" target="_blank">Discord</a> - Join our workshop channel for live discussion</li>
    <li><a href="https://whova.com/portal/webapp/0ViL6d@XFQZa4E-ctTBp/CommunityBoard/topic/3168489" target="_blank">Whova</a> - Post questions on the community board</li>
    <li><a href="https://underline.io/events/520/sessions?eventSessionId=21917&searchGroup=lecture" target="_blank">Underline</a> - For joining the live session</li>
    <li><a href="https://multiagents.org/2026_remote/" target="_blank">Remote Participation Portal</a> - Access limited workshop materials</li>
  </ul>
</div>

<div style={{margin: '1.5rem 0'}}>
  <h4 style={{marginBottom: '0.5rem'}}>Venue Map</h4>
  <img src="/2026_artifacts/aaai_26_map.png" alt="AAAI 2026 Venue Map" style={{maxWidth: '600px', width: '100%', borderRadius: '8px', boxShadow: '0 2px 8px rgba(0,0,0,0.15)'}}/>
</div>

![WMAC 2026 Banner Image](/2026_artifacts/banner-image.jpg)


# WMAC 2026: AAAI 2026 Bridge Program on Advancing LLM-Based Multi-Agent Collaboration

:::info
- (12/17) Updated the information on industrial demos and sponsors.
- (12/1) Updated the workshop agenda.
- (11/29) Updated the consolidated list of invited speakers for the workshop.
- (11/23) Decisions on oral / poster presentations are released to the authors.
- (11/13) Notification of acceptance is postponed to November 18, 2025.
- (11/1) The submission deadline is extended by 3 days to 11/3 (AOE).
- (10/19) Reminder: Paper submission deadline is October 31, 2025.
- (10/2) WMAC 2026 website and CFP are now live.
:::

We invite submissions to the **AAAI 2026 Bridge Program on Advancing LLM-Based Multi-Agent Collaboration**, to be held in Singapore during the AAAI 2026 conference (January 20, 2026).

## Overview:
This full-day program seeks to ignite discussion on cutting-edge research and challenges for bridging the gap between Large Language Models (LLMs) and Multi-Agent Systems (MAS) / Distributed AI. As LLMs continue to showcase the ability to coordinate multiple AI agents for complex problem-solving, the program will delve into pivotal open research questions that advance the understanding and potential of LLM-based multi-agent collaboration.

We invite submissions on a range of topics, including but not limited to:

- **Interoperability**: Design of protocols/methodologies that support a set of heterogeneous LLM-based agents to communicate, share knowledge, and collaborate reliably across platforms and modalities.
- **Coordination & Planning**: MAS methods (e.g., distributed planning, MARL-based methods) adapted to improve LLM-driven multi-agent systems that commonly use natural language as the interface of reasoning and communication.
- **Knowledge Sharing & Memory**: Architectures for stable, transparent sharing of context and memory among heterogeneous agents.
- **Scalability & Robustness**: Scaling from small teams of agents to large, dynamic populations while preventing instability.
- **Social Norms & Governance**: Embedding MAS insights on incentives, trust, and governance into LLM-driven agents to ensure alignment across a large number of agents.
- **Evaluation & Benchmarks**: Benchmarking the collaboration aspect of an LLM-based multi-agent system, such as extending the MAS benchmarks (e.g., PettingZoo, RoboCup) for LLM+MAS systems?

## Important Dates:

- Submission deadline: ~~October 31, 2025~~ **November 3, 2025 AOE** (Submission site: [link](https://openreview.net/group?id=AAAI.org/2026/Workshop/WMAC))
- Notification of acceptance: ~~November 14, 2025~~ **November 18, 2025**
- Workshop date: January 20, 2026


## Program Format:

The one-day program will feature invited talks, panel discussion, demos, oral and poster presentations. Similar to last year, we will elect one best paper from the submissions. Additional details on speakers and the schedule will be available on our website.

## Invited Speakers

<div className="speakers-grid" style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(300px, 1fr))', gap: '2rem', margin: '2rem 0'}}>
  <div className="speaker-card" style={{border: '1px solid #eee', borderRadius: '8px', padding: '1rem', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <img src="/2026_speakers/matthew_taylor.png" alt="Matthew E. Taylor" style={{width: '100%', height: '300px', objectFit: 'cover', borderRadius: '4px'}}/>
    <h3>Matthew E. Taylor</h3>
    <p style={{fontSize: '0.9rem', marginTop: '1rem', fontStyle: 'italic', color: '#555'}}>University of Alberta</p>
    <p style={{fontSize: '0.9rem'}}><strong>Title: </strong><br/><strong><em>Designing for Success: How should we build systems integrating multiple LLMs, RL agents, and humans?</em></strong></p>
    <p style={{fontSize: '0.85rem', marginTop: '1rem', color: '#444', lineHeight: '1.5'}}><strong>Abstract: </strong>Whether an agent is controlled by an LLM, an RL algorithm, or a human, when more than one agent interacts, you need to consider the entire multi-agent system. In this talk, I will first argue that any agentic AI system must consider the implicit or explicit human component, and some of the relevant best practices for researchers and practitioners. I will then discuss some of our more speculative work about how such systems, such as: How should such systems be formulated for successful alignment? What are the tradeoffs between different agent capabilities? How can we ensure successful adoption?</p>
  </div>

  <div className="speaker-card" style={{border: '1px solid #eee', borderRadius: '8px', padding: '1rem', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <img src="/2026_speakers/may_fung.png" alt="Yi R. (May) Fung" style={{width: '100%', height: '300px', objectFit: 'cover', borderRadius: '4px'}}/>
    <h3>Yi R. (May) Fung</h3>
    <p style={{fontSize: '0.9rem', marginTop: '1rem', fontStyle: 'italic', color: '#555'}}>Hong Kong University of Science and Technology</p>
    <p style={{fontSize: '0.9rem'}}><strong>Title: </strong><br/><strong><em>Ten Principles of Advanced Multimodal Agent Collaboration</em></strong></p>
    <p style={{fontSize: '0.85rem', marginTop: '1rem', color: '#444', lineHeight: '1.5'}}><strong>Abstract: </strong>The vision of an AI scientist, an agent that can autonomously discover, synthesize, and communicate new knowledge, is rapidly advancing beyond proof-of-concept. However, building such agents requires solving critical challenges at multiple stages of the research pipeline. In this talk, we will present a trilogy of works that address these core challenges. First, we will introduce Webwatcher, a vision-language deep research agent that breaks new frontiers by actively exploring and grounding its knowledge in real-world digital environments, moving beyond passive text analysis. Second, we will discuss our comprehensive survey, "Exploring Agentic MLLMs: A Survey for AI Scientists", which provides the essential roadmap for AI scientists in terms of structuring the architectures and capabilities needed for such multimodal autonomous systems. Finally, I will address the cornerstone of scholarly trust: attribution. We will present CiteGuard, a novel framework for faithful citation validation that ensures the outputs of AI research agents are verifiable and credible. Together, these works form a cohesive vision for the next generation of AI4Research, where agents are not just tools for literature review, but active, trustworthy partners in the scientific process, capable of perception, synthesis, and rigorous scholarly communication.</p>
  </div>

  <div className="speaker-card" style={{border: '1px solid #eee', borderRadius: '8px', padding: '1rem', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <img src="/2026_speakers/sophia_han.png" alt="Sophia Han" style={{width: '100%', height: '300px', objectFit: 'cover', borderRadius: '4px'}}/>
    <h3>Sophia Han</h3>
    <p style={{fontSize: '0.9rem', marginTop: '1rem', fontStyle: 'italic', color: '#555'}}>Stanford University</p>
    <p style={{fontSize: '0.9rem'}}><strong>Title: </strong><br/><strong><em>Multi-Agent Systems for Law</em></strong></p>
  </div>

  <div className="speaker-card" style={{border: '1px solid #eee', borderRadius: '8px', padding: '1rem', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <img src="/2026_speakers/virginia_dignum.png" alt="Virginia Dignum" style={{width: '100%', height: '300px', objectFit: 'cover', borderRadius: '4px'}}/>
    <h3>Virginia Dignum</h3>
    <p style={{fontSize: '0.9rem', marginTop: '1rem', fontStyle: 'italic', color: '#555'}}>Umeå University</p>
    <p style={{fontSize: '0.9rem'}}><strong>Title: </strong><br/><strong><em>Agentifying Agentic AI</em></strong></p>
  </div>
</div>

## Workshop Agenda
The workshop features invited talks, oral presentations, a lightning talk session, poster session, and panel discussion. More details on invited speakers and workshop agenda can be found on our website.

The table below shows a tentative workshop agenda. Note that the actual agenda will be adjusted according to the conference schedule.


| **Time** | **Duration** | **Session** |
|----------|--------------|-------------|
| **9:00** | 5 mins | **Opening Remarks** |
| **9:05** | 45 mins | **Invited Talk 1** – Yi R. (May) Fung (Hong Kong University of Science and Technology)<br/>*Ten Principles of Advanced Multimodal Agent Collaboration* |
| **9:50** | 10 mins | **WMAC History and Vision; Special Thanks to Sponsors** |
| **10:00** | 40 mins | **Invited Talk 2** – Sophia Han (Stanford University)<br/>*Multi-Agent Systems for Law* |
| **10:40** | 15 mins | **Coffee Break** |
| **10:55** | 20 mins | **Industrial Demo: PeakMojo**<br/>*Operationalizing Computational Psychometrics via Multi-Agent Consensus* (Bary Huang, CTO) |
| **11:15** | 25 mins | **Lightning Talks for Posters** |
| **11:40** | 50 mins | **Poster Session** |
| **12:30** | 80 mins | **Lunch + Social Time** |
| **13:50** | 45 mins | **Invited Talk 3** – Matthew E. Taylor (University of Alberta)<br/>*Designing for Success: How should we build systems integrating multiple LLMs, RL agents, and humans?* |
| **14:35** | 40 mins | **Specially Invited Oral Talk**<br/>*Agentifying Agentic AI*<br/>Virginia Dignum, Frank Dignum |
| **15:15** | 20 mins | **Fireside Chat & Panel** |
| **15:35** | 15 mins | **Invited Talk 4** – Haodong Zhao<br/>*Disagreements in Reasoning: How a Model's Thinking Process Dictates Persuasion in Multi-Agent Systems* |
| **15:50** | 30 mins | **Coffee Break** |
| **16:20** | 20 mins | **Oral Presentation – Paper 2**<br/>*Utility-Aware Task Decomposition and Exchange across LLM Agents*<br/>Shunta Kimura, Takuya Hiraoka, Ryota Higa, Yoshimasa Tsuruoka, Katsuhide Fujita |
| **16:40** | 20 mins | **Oral Presentation – Paper 3**<br/>*Multi-Agent Collaborative Reward Design for Enhancing Reasoning in Reinforcement Learning*<br/>Pei Yang, Ke Zhang, Ji Wang, Xiao Chen, Yuxin Tang, Yiqun Duan, Tianyu Shi |
| **17:00** | 15 mins | **Coffee Break** |
| **17:15** | 40 mins | **Industrial Demo Session** (2 demos, 20 mins each)<br/>1. *Qoder Multi-Agent Coding Platform* (Yu Hang, Product Lead, Bright Zenith)<br/>2. *MassGen for Multi-Agent Generation* (Kevin Noel, Core Contributor, AG2) |
| **17:55** | 20 mins | **Oral Presentation – Paper 4**<br/>*Toward Socially Aware Multi-Agent Systems: Measuring Group-Level Influence of LLM Agents*<br/>Tianqi Song, Yugin Tan, Zicheng Zhu, Feng Yibin, Yi-Chieh Lee |
| **18:15** | 10 mins | **Award & Closing Remarks** |

## Accepted Papers


<div style={{margin: '2rem 0'}}>
  <h3 style={{marginBottom: '1.5rem', color: '#2e3440', borderBottom: '2px solid #3b4252', paddingBottom: '0.5rem'}}>Oral Presentations</h3>
  <div style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(300px, 1fr))', gap: '1.5rem'}}>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>Toward Socially Aware Multi-Agent Systems: Measuring Group-Level Influence of LLM Agents</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Tianqi Song, Yugin Tan, Zicheng Zhu, Feng Yibin, Yi-Chieh Lee</p>
      <p style={{marginBottom: 0}}><a href="/2026_papers/socially_aware_multi_agent.pdf" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>PDF</a></p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>Multi-Agent Collaborative Reward Design for Enhancing Reasoning in Reinforcement Learning</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Pei Yang, Ke Zhang, Ji Wang, Xiao Chen, Yuxin Tang, Yiqun Duan, Tianyu Shi</p>
      <p style={{marginBottom: 0}}><a href="https://arxiv.org/abs/2511.16202" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>arXiv</a></p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>Agentifying Agentic AI</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Virginia Dignum, Frank Dignum</p>
      <p style={{marginBottom: 0}}><a href="https://arxiv.org/abs/2511.17332" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>arXiv</a></p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>Utility-Aware Task Decomposition and Exchange across LLM Agents</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Shunta Kimura, Takuya Hiraoka, Ryota Higa, Yoshimasa Tsuruoka, Katsuhide Fujita</p>
      <p style={{marginBottom: 0}}><a href="/2026_papers/utility_aware_task_decomposition.pdf" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>PDF</a></p>
    </div>
  </div>
</div>

<div style={{margin: '3rem 0'}}>
  <h3 style={{marginBottom: '1.5rem', color: '#2e3440', borderBottom: '2px solid #3b4252', paddingBottom: '0.5rem'}}>Poster Presentations</h3>
  <div style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(300px, 1fr))', gap: '1.5rem'}}>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>Hierarchical Multi-Agent System for Data-Efficient Alloy Discovery with Closed-Loop Experimental Feedback</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Mahule Roy, Subhas Roy</p>
      <p style={{marginBottom: 0}}><a href="/2026_papers/hierarchical_alloy_discovery.pdf" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>PDF</a></p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>Goal-Aware Identification and Rectification of Misinformation in Multi-Agent Systems</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Zherui Li, Yan Mi, Zhenhong Zhou, Houcheng Jiang, Guibin Zhang, Kun Wang, Junfeng Fang</p>
      <p style={{marginBottom: 0}}><a href="https://arxiv.org/abs/2506.00509" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>arXiv</a></p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>AED: Automatic Discovery of Effective and Diverse Vulnerabilities for Autonomous Driving Policy with Large Language Models</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Le Qiu, Zelai Xu, Qixin Tan, Wenhao Tang, Chao Yu, Yu Wang</p>
      <p style={{marginBottom: 0}}><a href="https://arxiv.org/abs/2503.20804" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>arXiv</a></p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>Trust-MA: Trust-Based Multi-Agent Framework for Cooperative On-Ramp Merging Integrating Large Language Models</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Tianyi Wang, Tianyi Zeng, Yangyang Wang, Junfeng Jiao, Christian Claudel</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>Scalable and Accurate Graph Reasoning with LLM-Based Multi-Agents</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Yuwei Hu, Runlin Lei, Xinyi Huang, Zhewei Wei, Yongchao Liu</p>
      <p style={{marginBottom: 0}}><a href="https://arxiv.org/abs/2410.05130" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>arXiv</a></p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>Learning Collaborative Reasoning Strategies Through Trust-Weighted Multi-Agent Consensus</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Projan Shakya, Kristina Ghimire, Kashish Bataju, Ashwini Mandal, Sadikshya Gyawali, Manish Awale, Manish Dahal, Shital Adhikari, Sanjay Rijal, Young You, Vaghawan Ojha</p>
      <p style={{marginBottom: 0}}><a href="/2026_papers/collaborative_reasoning_trust.pdf" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>PDF</a></p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>Multi-Agent Video Recommenders: Evolution, Patterns, and Open Challenges</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Srivaths Ranganathan, Abhishek Dharmaratnakar, Anushree Sinha, Debanshu Das</p>
      <p style={{marginBottom: 0}}><a href="/2026_papers/multi_agent_video_recommenders.pdf" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>PDF</a></p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>Coordinating LLMs via Debate Trees: Hierarchical Decomposition Improves Truthfulness</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Xiang Fu, Kevin Gold</p>
      <p style={{marginBottom: 0}}><a href="https://repo.xiangfu.site/research/tsd/tsd_aaai_wmac26.pdf" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>PDF</a></p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}>AgentGit: A Version Control Framework for Reliable and Scalable LLM-Powered Multi-Agent Systems</h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: '0.5rem'}}>Yang Li, Siqi Ping, Xiyu Chen, Xiaojian Qi, Zigan Wang, Ye Luo, Xiaowei Zhang</p>
      <p style={{marginBottom: 0}}><a href="https://arxiv.org/abs/2511.00628" target="_blank" style={{fontSize: '0.85rem', color: '#5e81ac'}}>arXiv</a></p>
    </div>
  </div>
</div>

## Attendance

- All presentations will be in-person.
- In-person participation is encouraged but remote participation will be supported for talks.
- All workshop attendees (in-person/remote) need to register for the workshop section of AAAI 2026. 


## Sponsors:

<div className="sponsors-grid" style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(250px, 1fr))', gap: '2rem', margin: '2rem 0'}}>
  <div className="sponsor-card" style={{textAlign: 'center', padding: '1.5rem', border: '1px solid #eee', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <a href="https://linkedin.com" target="_blank" rel="noopener noreferrer">
      <img src="/2026_sponsors/linkedin_logo.png" alt="LinkedIn" style={{maxWidth: '200px', height: 'auto', margin: '0 auto'}}/>
    </a>
  </div>

  <div className="sponsor-card" style={{textAlign: 'center', padding: '1.5rem', border: '1px solid #eee', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <a href="https://aws.amazon.com" target="_blank" rel="noopener noreferrer">
      <img src="/2026_sponsors/aws_logo.png" alt="AWS" style={{maxWidth: '200px', height: 'auto', margin: '0 auto'}}/>
    </a>
  </div>

  <div className="sponsor-card" style={{textAlign: 'center', padding: '1.5rem', border: '1px solid #eee', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <a href="https://www.youware.com" target="_blank" rel="noopener noreferrer">
      <img src="/2026_sponsors/youware_logo.png" alt="YouWare" style={{maxWidth: '200px', height: 'auto', margin: '0 auto'}}/>
    </a>
    <p style={{marginTop: '1rem', fontSize: '0.9rem'}}><a href="https://docs.youware.com/introduction/quickstartguide" target="_blank" rel="noopener noreferrer">Quick Start Guide →</a></p>
  </div>
</div>

## Organizers:

<div className="organizers-grid" style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(200px, 1fr))', gap: '1.5rem', margin: '2rem 0'}}>
  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/alborz_geramifard.jpg" alt="Alborz Geramifard" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Alborz Geramifard</h4>
    <p style={{fontSize: '0.9rem', color: '#666'}}>LinkedIn</p>
  </div>

  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/alex_marin.png" alt="Alex Marin" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Alex Marin</h4>
    <p style={{fontSize: '0.9rem', color: '#666'}}>Thomson Reuters</p>
  </div>

  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2026_organizers/jeffrey_cho.jpg" alt="Jeffrey Cho" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Jeffrey Cho</h4>
    <p style={{fontSize: '0.9rem', color: '#666'}}>University of Pennsylvania</p>
  </div>


  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/raphael_shu.jpeg" alt="Raphael Shu" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Raphael Shu</h4>
    <div style={{margin: '-0.3rem 0 0.5rem'}}><span style={{display: 'inline-block', fontSize: '0.7rem', padding: '2px 8px', backgroundColor: '#4a90e2', color: 'white', borderRadius: '12px'}}>Workshop Chair</span></div>
    <p style={{fontSize: '0.9rem', color: '#666'}}>OpenAgents</p>
  </div>

  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/weiyan_shi.jpg" alt="Weiyan Shi" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Weiyan Shi</h4>
    <p style={{fontSize: '0.9rem', color: '#666'}}>Northeastern University</p>
  </div>

  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/tao_yu.jpeg" alt="Tao Yu" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Tao Yu</h4>
    <p style={{fontSize: '0.9rem', color: '#666'}}>The University of Hong Kong</p>
  </div>

  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/yi_zhang.png" alt="Yi Zhang" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Yi Zhang</h4>
    <p style={{fontSize: '0.9rem', color: '#666'}}>Amazon AWS GenAI</p>
  </div>

  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2026_organizers/yusen_zhang.png" alt="Yusen Zhang" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Yusen Zhang</h4>
    <div style={{margin: '-0.3rem 0 0.5rem'}}><span style={{display: 'inline-block', fontSize: '0.7rem', padding: '2px 8px', backgroundColor: '#4a90e2', color: 'white', borderRadius: '12px'}}>Co-Chair</span></div>
    <p style={{fontSize: '0.9rem', color: '#666'}}>Columbia University</p>
  </div>
</div>

## Industrial Demos:

<div className="demos-grid" style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(250px, 1fr))', gap: '2rem', margin: '2rem 0'}}>
  <div className="demo-card" style={{textAlign: 'center', padding: '1.5rem', border: '1px solid #eee', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <a href="https://www.peakmojo.com" target="_blank" rel="noopener noreferrer">
      <img src="/2026_sponsors/peakmojo_logo.png" alt="PeakMojo" style={{maxWidth: '120px', height: 'auto', margin: '0 auto'}}/>
    </a>
    <p style={{marginTop: '1rem', fontSize: '0.9rem', color: '#666'}}>Operationalizing Computational Psychometrics via Multi-Agent Consensus</p>
  </div>

  <div className="demo-card" style={{textAlign: 'center', padding: '1.5rem', border: '1px solid #eee', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <a href="https://ag2.ai" target="_blank" rel="noopener noreferrer">
      <img src="/2026_sponsors/ag2_logo.png" alt="AG2" style={{maxWidth: '120px', height: 'auto', margin: '0 auto'}}/>
    </a>
    <p style={{marginTop: '1rem', fontSize: '0.9rem', color: '#666'}}>MassGen for Multi-Agent Generation</p>
  </div>

  <div className="demo-card" style={{textAlign: 'center', padding: '1.5rem', border: '1px solid #eee', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <a href="https://qoder.com/" target="_blank" rel="noopener noreferrer">
      <img src="/2026_sponsors/qocoder_logo.png" alt="Qoder" style={{maxWidth: '150px', height: 'auto', margin: '0 auto'}}/>
    </a>
    <p style={{marginTop: '1rem', fontSize: '0.9rem', color: '#666'}}>Qoder - The Agentic Coding Platform</p>
  </div>
</div>

## Submission Guidelines:

We welcome both short papers (up to 4 pages) and long papers (up to 8 pages) following the AAAI format. Submissions may include recently published work, under-review papers, work in progress, and position papers. All submissions will undergo peer review through a **double-blind** process. While publication in our program is non-archival, accepted papers will be featured on our website with the author's permission.

:::info
- Please submit your paper with author names anonymized.
- The page limit (4 pages for short and 8 pages for long papers) does not include references or appendices. The references and appendices can have unlimited number of pages.
:::

## Submission Site:
Please submit your work via: [OpenReview Submission Link](https://openreview.net/group?id=AAAI.org/2026/Workshop/WMAC)

## Contact:
For questions, please contact us at pc@multiagents.org

More information can be found on our workshop website: https://multiagents.org

We look forward to your submissions and to seeing you at the workshop!
