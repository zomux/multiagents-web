---
sidebar_position: 1
hide_table_of_contents: true
title: Overview
---

:::info
<div style={{display: 'flex', alignItems: 'center', gap: '2rem'}}>
  <div style={{flex: '1', display: 'flex', flexDirection: 'column', justifyContent: 'flex-start'}}>
    **On-site workshop attendance instructions:**

    WMAC 2025 will be held on March 4, 2025. Workshop room is **Room 123** (Pennsylvania Convention Center).
  </div>
  <div style={{flexShrink: '0'}}>
    <img src="/2025_artifacts/direction.png" alt="Direction to Room 123" style={{width: '500px', maxWidth: '100%', height: 'auto', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}/>
  </div>
</div>
:::


:::info
- (2/8) Updated accepted papers for WMAC 2025.
- (1/6) Updated with full information of accepted papers and invited speakers. We will update the workshopagenda soon.
- (12/17) All paper decisions and reviews have been released. For accepted papers, we will send out another email notifying the presentation format and camera-ready deadline. Please note that early registration of AAAI 2025 is now open until 12/19 (11:59 PM ET), please take your time to register. Make sure your registration covers the workshop session for WMAC 2025. For students presenting at the workshop, if you require waiver of the workshop registration fee, please contact us.
- (12/1) To reviewers: Review deadline is Dec 13th. Please let us know if you cannot submit your review by then.
- (11/30) We have assigned reviewers for the submitted papers. Reviewers will be notified via email, review deadline is Dec 13th.
- (11/24) Due to multiple requests, we decided to extend the submission deadline by 3 days to November 27th (AOE). The date for notification of acceptance is also adjusted accordingly.
- (11/22) Please contact pc@multiagents.org if you have any question on submission.
- (11/20) We updated invited speakers for the workshop and added notes for submission.
- (11/13) We updated invited speakers for the workshop.
:::

# WMAC 2025: AAAI 2025 Workshop on Advancing LLM-Based Multi-Agent Collaboration

We invite participants to the **AAAI 2025 Workshop on Advancing LLM-Based Multi-Agent Collaboration**, to be held in Philadelphia during the AAAI 2025 conference on March 4, 2025. Workshop room is **Room 123**.

## Overview:
This full-day workshop seeks to ignite discussion on cutting-edge research areas and challenges associated with multi-agent collaboration driven by large language models (LLMs). As LLMs continue to showcase the ability to coordinate multiple AI agents for complex problem-solving, the workshop will delve into pivotal open research questions that advance the understanding and potential of LLM-based multi-agent collaboration.

We welcome submissions on topics including, but not limited to:

- Multi-agent collaboration structures, hierarchy and decision making
- Cross-agent knowledge sharing 
- Inter-agent communication protocols
- Distributed and decentralized agents
- Multi-agent group behavior learning
- Strategic planning for multi-agent problem-solving
- Guardrails and responsible behaviors in multi-agent systems

## Important Dates:

- ~~Submission deadline: November 24, 2024 AOE -> November 27, 2024 AOE~~ 
- ~~Paper Review Deadline: December 13, 2024~~
- ~~Notification of acceptance: December 9, 2024 -> December 16, 2024~~ 
- ~~Paper link submission deadline: January 31, 2025~~
- Workshop date: March 4th

## Invited Speakers

Following are confirmed invited speakers, ordered by last name:

<div className="speakers-grid" style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(300px, 1fr))', gap: '2rem', margin: '2rem 0'}}>
  <div className="speaker-card" style={{border: '1px solid #eee', borderRadius: '8px', padding: '1rem', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <img src="/2025_speakers/vivian_chen.jpg" alt="Vivian Chen" style={{width: '100%', height: '300px', objectFit: 'cover', borderRadius: '4px'}}/>
    <h3>Vivian Chen</h3>
    <p style={{fontSize: '0.9rem'}}><em>Professor, National Taiwan University</em></p>
    <p style={{fontSize: '0.9rem'}}>Yun-Nung (Vivian) Chen is currently a professor in the Department of Computer Science & Information Engineering at National Taiwan University. She earned her Ph.D. degree from Carnegie Mellon University, where her research interests focus on spoken dialogue systems and natural language processing. She was recognized as the World's Top 2% Scientists in her 2023 impact, the Taiwan Outstanding Young Women in Science and received Google Faculty Research Awards, Amazon AWS Machine Learning Research Awards, MOST Young Scholar Fellowship, and FAOS Young Scholar Innovation Award. Her team was selected to participate in the first Alexa Prize TaskBot Challenge in 2021. Prior to joining National Taiwan University, she worked in the Deep Learning Technology Center at Microsoft Research Redmond.</p>
  </div>

  <div className="speaker-card" style={{border: '1px solid #eee', borderRadius: '8px', padding: '1rem', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <img src="/2025_speakers/kyunghyun_cho.jpg" alt="Kyunghyun Cho" style={{width: '100%', height: '300px', objectFit: 'cover', borderRadius: '4px'}}/>
    <h3>Kyunghyun Cho</h3>
    <p style={{fontSize: '0.9rem'}}><em>Professor, New York University</em></p>
    <p style={{fontSize: '0.9rem'}}>Kyunghyun Cho is a professor of computer science and data science at New York University and an executive director of frontier research at the Prescient Design team within Genentech Research & Early Development (gRED). He is also a CIFAR Fellow of Learning in Machines & Brains and an Associate Member of the National Academy of Engineering of Korea. He served as a (co-)Program Chair of ICLR 2020, NeurIPS 2022 and ICML 2022. He is also a founding co-Editor-in-Chief of the Transactions on Machine Learning Research (TMLR). He was a research scientist at Facebook AI Research from June 2017 to May 2020 and a postdoctoral fellow at University of Montreal until Summer 2015. He received the Samsung Ho-Am Prize in Engineering in 2021.</p>
  </div>

  <div className="speaker-card" style={{border: '1px solid #eee', borderRadius: '8px', padding: '1rem', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <img src="/2025_speakers/yilun_du.png" alt="Yilun Du" style={{width: '100%', height: '300px', objectFit: 'cover', borderRadius: '4px'}}/>
    <h3>Yilun Du</h3>
    <p style={{fontSize: '0.9rem'}}><em>Google DeepMind</em></p>
    <p style={{fontSize: '0.9rem'}}>Yilun Du is currently a senior research scientist at Google Deepmind and an incoming assistant professor at Harvard University. He received his PhD at MIT and received a NSF graduate fellowship. His work has received an outstanding paper award at ICLR.</p>
  </div>

  <div className="speaker-card" style={{border: '1px solid #eee', borderRadius: '8px', padding: '1rem', boxShadow: '0 2px 4px rgba(0,0,0,0.1)'}}>
    <img src="/2025_speakers/katia_sycara.png" alt="Katia Sycara" style={{width: '100%', height: '300px', objectFit: 'cover', borderRadius: '4px'}}/>
    <h3>Katia Sycara</h3>
    <p style={{fontSize: '0.9rem'}}><em>Professor, Carnegie Mellon University</em></p>
    <p style={{fontSize: '0.9rem'}}>Katia Sycara holds the Edward Fredkin Research Chair in Robotics at the School of Computer Science at Carnegie Mellon University and is Associate Director for Faculty at the Robotics Institute. For the past 5 years she was the Director of the AFOSR Center of Excellence for Trustworthy Autonomy. Her research interests are in AI/ML, multi-agent and multi-robot systems, human robot teaming. She is a Fellow of IEEE, Fellow of the AAAI, and the recipient of the ACM/SIGART Agents Research Award and the INFORMS Lifetime Research Award. She has received 2 Influential 10-year paper awards and multiple best paper awards.</p>
  </div>
</div>

## Accepted Papers


<div style={{margin: '2rem 0'}}>
  <h3 style={{marginBottom: '1.5rem', color: '#2e3440', borderBottom: '2px solid #3b4252', paddingBottom: '0.5rem'}}>Oral Presentations</h3>
  <div style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(300px, 1fr))', gap: '1.5rem'}}>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="https://arxiv.org/pdf/2406.11776" target="_blank">Improving Multi-Agent Debate with Sparse Communication Topology</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Yunxuan Li, Yibing Du, Jiageng Zhang, Le Hou, Peter Grabowski, Yeqing Li, Eugene Ie</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="/2025_artifacts/talking_vehicles_cooperative_driving_via_natural_language.pdf" target="_blank">Talking Vehicles: Cooperative Driving via Natural Language</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Jiaxun Cui, Chen Tang, Jarrett Holtz, Janice Nguyen, Alessandro G Allievi, Hang Qiu, Peter Stone</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="/2025_artifacts/aligning_compound_ai_systems_via_system_level_dpo.pdf" target="_blank">Aligning Compound AI Systems via System-level DPO</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Xiangwen Wang, Yibo Jacky Zhang, Zhoujie Ding, Katherine Tsai, Sanmi Koyejo</p>
    </div>
  </div>
</div>

<div style={{margin: '3rem 0'}}>
  <h3 style={{marginBottom: '1.5rem', color: '#2e3440', borderBottom: '2px solid #3b4252', paddingBottom: '0.5rem'}}>Poster Presentations</h3>
  <div style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(300px, 1fr))', gap: '1.5rem'}}>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="https://arxiv.org/pdf/2407.11384" target="_blank">InvAgent: A Large Language Model based Multi-Agent System for Inventory Management in Supply Chains</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Yinzhu Quan, Zefang Liu</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="/2025_artifacts/i_apologize_for_my_actions.pdf" target="_blank">"I apologize for my actions": Emergent Properties and Technical Challenges of Generative Agents</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>N'yoma Diamond, Soumya Banerjee</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="https://arxiv.org/pdf/2411.05828" target="_blank">Agentic AI Multi-Agent Interoperability Extension for Managing Multiparty Conversations</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Diego Gosmar, Deborah A. Dahl, Emmett Coin, David Attwater</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="/2025_artifacts/masr_multi_agent_system_with_reflection_for_the_abstraction_and_reasoning_corpus.pdf" target="_blank">MASR: Multi-Agent System with Reflection for the Abstraction and Reasoning Corpus</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Kiril Bikov, Mikel Bober-Irizar, Soumya Banerjee</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="/2025_artifacts/agentseval_enhancing_llm_as_a_judge_via_multi_agent_collaboration.pdf" target="_blank">AgentsEval: Enhancing LLM-as-a-Judge via Multi-Agent Collaboration</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Yiyue Qian, Shinan Zhang, Yun Zhou, Haibo Ding, Diego A. Socolinsky, Yi Zhang</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="https://arxiv.org/pdf/2412.21102" target="_blank">Exploring and Controlling Diversity in LLM-Agent Conversation</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>KuanChao Chu, Yi-Pei Chen, Hideki Nakayama</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="https://arxiv.org/pdf/2412.06808" target="_blank">Effect of Adaptive Communication Support on Human-AI Collaboration</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Shipeng Liu, FNU Shrutika, Boshen Zhang, Zhehui Huang, Feifei Qian</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="/2025_artifacts/dont_just_demo_teach_me_the_principles.pdf" target="_blank">Don't Just Demo, Teach Me the Principles: A Principle-Based Multi-Agent Prompting Strategy for Text Classification</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Peipei Wei</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="http://arxiv.org/pdf/2502.01450" target="_blank">Simulating Rumor Spreading in Social Networks using LLM agents</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Tianrui Hu, Dimitrios Liakopoulos, Xiwen Wei, Radu Marculescu, Neeraja J Yadwadkar</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="https://arxiv.org/pdf/2501.06322" target="_blank">Demystifying LLM-based Multi-Agent Collaboration</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Khanh-Tung Tran, Dung Dao, Duong Minh Nguyen, Viet Quoc Pham, Barry O'Sullivan, Hoang D. Nguyen</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="https://drive.google.com/file/d/1ebpcJaUT3P1Is1AaUSKQOHlM936tSv9N/view?usp=sharing" target="_blank">AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Huizi Yu, Jiayan Zhou, Lingyao Li, Themistocles L. Assimes, Xin Ma, Danielle Bitterman, Lizhou Fan</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="/2025_artifacts/reliable_decision_making_for_multi_agent_llm_systems.pdf" target="_blank">Reliable Decision-Making for Multi-Agent LLM Systems</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Xian Yeow Lee, Shunichi Akatsuka, Aman Kumar, Lasitha Vidyaratne, Ahmed K. Farahat, Chetan Gupta</p>
    </div>
    <div style={{backgroundColor: '#fff', padding: '1.5rem', borderRadius: '8px', boxShadow: '0 2px 4px rgba(0,0,0,0.1)', border: '1px solid #e5e9f0'}}>
      <h4 style={{color: '#2e3440', marginTop: 0}}><a href="/2025_artifacts/a_multi_agent_approach_for_iterative_refinement_in_visual_content_generation.pdf" target="_blank">A Multi-Agent Approach for Iterative Refinement in Visual Content Generation</a></h4>
      <p style={{color: '#4c566a', fontSize: '0.9rem', marginBottom: 0}}>Adithya S Kolavi, Achala Nayak, Nigel Teofilo Dias, Srinidhi Somayaji P, Ramamoorthy Srinath</p>
    </div>
  </div>
</div>

## Workshop Agenda
The workshop features invited talks, oral presentations, a lightning talk session, poster session, and panel discussion. More details on invited speakers and workshop agenda can be found on our website.

The table below shows a tentative workshop agenda. Note that the actual agenda will be adjusted according to the conference schedule.


| **Time**         | **Duration** | **Session**                             |
|-------------------|--------------|-----------------------------------------|
| **9:00 – 9:05**  | 5 mins       | **Opening Remarks**                     |
| **9:05 – 9:40**  | 35 mins      | **Invited Talk 1 - Yilun Du**<br/>*Reasoning with Language Models through Multiagent Collaboration*                      |
| **9:40 – 10:15** | 35 mins      | **Invited Talk 2 - Kyunghyun Cho**<br/>*A multi-modal, multi-agent system - A minimalistic framework to study multi-agent systems*                      |
| **10:15 – 10:30**| 15 mins      | **Oral Presentation – Paper 1**<br/>*Talking Vehicles: Cooperative Driving via Natural Language*         |
| **10:30 – 11:00**| 30 mins      | **Break** (Light refreshments)          |
| **11:00 – 11:15**| 15 mins      | **Oral Presentation – Paper 2**<br/>*Aligning Compound AI Systems via System-level DPO*         |
| **11:15 – 11:35**| 20 mins      | **Lightning Talk Session**              |
| **11:35 – 12:30**| 55 mins      | **Poster Session**                      |
| **12:30 – 14:00**| 90 mins      | **Lunch**                               |
| **14:00 – 14:35**| 35 mins      | **Invited Talk 3 - Vivian Chen**<br/>*Optimizing Interaction and Intelligence --- Multi-Agent Simulation and Collaboration for Personalized Marketing and Advanced Reasoning*                      |
| **14:35 – 15:10**| 35 mins      | **Invited Talk 4 - Katia Sycara**<br/>*LLM based Teamwork: Promises and Challenges*                      |
| **15:10 – 15:25**| 15 mins      | **Oral Presentation – Paper 3**<br/>*Improving Multi-Agent Debate with Sparse Communication Topology*         |
| **15:25 – 15:30**| 5 mins       | **Buffer Time**                         |
| **15:30 – 16:00**| 30 mins      | **Break** (Light refreshments)          |
| **16:00 – 16:45**| 45 mins      | **Panel Discussion**                    |
| **16:45 – 17:00**| 15 mins      | **Award & Closing Remarks**             |

## Attendance

- All presentations will be in-person. 
- In-person participation is encouraged but remote participation will be supported for talks. 
- All workshop attendees (in-person/remote) need to register for the workshop section of AAAI 2025. 

## Organizers:

<div className="organizers-grid" style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(200px, 1fr))', gap: '1.5rem', margin: '2rem 0'}}>
  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/alborz_geramifard.jpg" alt="Alborz Geramifard" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Alborz Geramifard</h4>
    <p style={{fontSize: '0.9rem', color: '#666'}}>Meta</p>
  </div>

  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/alex_marin.png" alt="Alex Marin" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Alex Marin</h4>
    <p style={{fontSize: '0.9rem', color: '#666'}}>Microsoft</p>
  </div>

  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/raphael_shu.jpeg" alt="Raphael Shu" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Raphael Shu</h4>
    <div style={{margin: '-0.3rem 0 0.5rem'}}><span style={{display: 'inline-block', fontSize: '0.7rem', padding: '2px 8px', backgroundColor: '#4a90e2', color: 'white', borderRadius: '12px'}}>Workshop Chair</span></div>
    <p style={{fontSize: '0.9rem', color: '#666'}}>Amazon AWS GenAI</p>
  </div>

  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/weiyan_shi.jpg" alt="Weiyan Shi" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Weiyan Shi</h4>
    <p style={{fontSize: '0.9rem', color: '#666'}}>Northeastern University</p>
  </div>

  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/tao_yu.jpeg" alt="Tao Yu" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Tao Yu</h4>
    <p style={{fontSize: '0.9rem', color: '#666'}}>The University of Hong Kong</p>
  </div>

  <div className="organizer-card" style={{textAlign: 'center', padding: '1rem'}}>
    <img src="/2025_organizers/yi_zhang.png" alt="Yi Zhang" style={{width: '180px', height: '180px', objectFit: 'cover', borderRadius: '50%', margin: '0 auto'}}/>
    <h4 style={{margin: '1rem 0 0.5rem'}}>Yi Zhang</h4>
    <p style={{fontSize: '0.9rem', color: '#666'}}>Amazon AWS GenAI</p>
  </div>
</div>


## Submission Guidelines:

We welcome both short papers (up to 4 pages) and long papers (up to 8 pages) following the AAAI format. Submissions may include recently published work, under-review papers, work in progress, and position papers. All submissions will undergo peer review through a single-blind process. While workshop publication is non-archival, accepted papers will be featured on our website with author permission.

:::info
- Please submit your paper with author names anonymized.
- The page limit (4 pages for short and 8 pages for long papers) does not include references or appendices. The references and appendices can have unlimited number of pages.
:::

**More details on review process** We have configured the OpenReview system so that the chairs can see the author names and assign reviewers accordingly. However, when the papers are reviewed, the author names will be blind to paper reviewers.

## Submission site:
Please submit your work via: [OpenReview Submission Link](https://openreview.net/group?id=AAAI.org/2025/Workshop/WMAC)

## Review Guidelines:
As WMAC 2025 will be hosted at AAAI, we would like to remind reviewers to follow AAAI review policy that all submissions have to be kept confidential. In your review, please be explicit about the pros and cons and provide constructive feedback for the authors.

The submitted papers cannot be uploaded into any system that does not ensure that they are not shared with others. This includes also prompting Large Language Models with papers or parts of them, because these systems may disclose part of the prompt to other users.

We would also like to remind reviewers that they are fully responsible for the entire content of their reviews, so tools can be used to improve the wording of the review but not to generate its content.


## Contact:
For questions, please contact us at pc@multiagents.org

More information can be found on our workshop website: https://multiagents.org

We look forward to your submissions and to seeing you at AAAI 2025!